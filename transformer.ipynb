{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:04.419848Z","iopub.status.busy":"2023-06-01T07:41:04.419073Z","iopub.status.idle":"2023-06-01T07:41:09.973017Z","shell.execute_reply":"2023-06-01T07:41:09.971761Z","shell.execute_reply.started":"2023-06-01T07:41:04.419798Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import json\n","import re\n","import os\n","import math\n","import jieba\n","from tqdm import tqdm\n","from collections import Counter\n","from torchtext.data import get_tokenizer\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset,DataLoader\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","import IPython.display as display"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["SOS_ID = 0\n","EOS_ID = 1\n","UNK_ID = 2\n","PAD_ID = 3\n","en_vocab_size, ch_vocab_size = 7184, 16251\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","lr = 1e-6\n","d_model = 256\n","d_ff = 1024\n","num_heads = 8\n","num_layers = 6\n","num_epochs = 600\n","batch_size = 64"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 数据预处理"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 处理数据集"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def is_contain_chinese(check_str):\n","    for ch in check_str:\n","        if u'\\u4e00' <= ch <= u'\\u9fff':\n","            return True\n","    return False\n","\n","def is_contain_english(check_str):\n","    return bool(re.search(f'[a-zA-Z]+',check_str))\n","\n","# with open('cmn-eng/cmn.txt','r') as f:\n","#     i=0\n","#     english = []\n","#     chinese = []\n","#     for line in f.readlines():\n","#         en_sen = \"\"\n","#         ch_sen = \"\"\n","#         is_eng =True\n","#         for word in line.split():\n","#             if is_eng:\n","#                 if is_contain_chinese(word):\n","#                     is_eng=False\n","#                     ch_sen += word + \" \"\n","#                 else:\n","#                     en_sen += word + \" \"\n","#             else:\n","#                 if is_contain_english(word):\n","#                     break\n","#                 else:\n","#                     ch_sen += word + \" \"\n","\n","#         english.append(en_sen)\n","#         chinese.append(ch_sen)\n","    \n","#     tokenizer = get_tokenizer('basic_english')\n","#     with open('cmn-eng/english.txt', 'w') as ef:\n","#         for sen in english:\n","#             sen = tokenizer(sen)\n","#             for word in sen:\n","#                 ef.write(word + \" \")\n","#             ef.write(\"\\n\")\n","#         ef.close()\n","\n","#     with open('cmn-eng/chinese.txt', 'w') as cf:\n","#         for sen in chinese:\n","#             sen = list(jieba.cut(sen))\n","#             for word in sen:\n","#                 cf.write(word + \" \")\n","#             cf.write(\"\\n\")\n","#         cf.close()\n","#     f.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:09.976432Z","iopub.status.busy":"2023-06-01T07:41:09.975630Z","iopub.status.idle":"2023-06-01T07:41:09.996751Z","shell.execute_reply":"2023-06-01T07:41:09.994886Z","shell.execute_reply.started":"2023-06-01T07:41:09.976394Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def create_vocab(sentences, max_element=None):\n","    \"\"\"Note that max_element includes special characters\"\"\"\n","    default_list = ['<sos>', '<eos>', '<unk>', '<pad>']\n","    char_set = Counter()\n","    for sentence in sentences:\n","        temp_set = Counter(sentence)\n","        char_set.update(temp_set)\n","\n","    if max_element is None:\n","        return default_list + list(char_set.keys())\n","    else:\n","        max_element -= 4\n","        words_freq = char_set.most_common(max_element) # 出现频率最大的前n个 返回元组类型\n","        words, freq = zip(*words_freq)\n","        return default_list + list(words)\n","    \n","def save_vocab(vocab, name):\n","    with open(name, 'w') as f:\n","        for a in vocab:\n","            f.write(a + \" \")\n","            \n","def load_vocab(name):\n","    with open(name, 'r') as f:\n","        a = f.read()\n","    return a.split()\n","\n","def sentence_to_tensor(sentences, vocab):\n","    indexs = []\n","    for sentence in sentences:\n","        index = []\n","        for char in sentence:\n","            if char in vocab:\n","                index.append(vocab.index(char))\n","            else:\n","                index.append(UNK_ID)\n","        indexs.append(np.array(index))\n","    return indexs\n","\n","def tensor_to_sentence(indexs, vocab):\n","    sentence = \"\"\n","    for index in indexs:\n","        sentence += vocab[index] + \" \"\n","    return sentence[:-1]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:09.999310Z","iopub.status.busy":"2023-06-01T07:41:09.998907Z","iopub.status.idle":"2023-06-01T07:41:10.023833Z","shell.execute_reply":"2023-06-01T07:41:10.022608Z","shell.execute_reply.started":"2023-06-01T07:41:09.999277Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["## 构造英文词典\n","# max_element = en_vocab_size \n","# default_list = ['<sos>', '<eos>', '<unk>', '<pad>']\n","# char_set = Counter()\n","# with open('cmn-eng/english.txt','r') as ff:\n","#     for line in ff.readlines():\n","#         sentence = line.split()\n","#         temp_set = Counter(sentence)\n","#         char_set.update(temp_set)\n","# print(len(char_set))\n","# max_element -= 4\n","# words_freq = char_set.most_common(max_element) # 出现频率最大的前n个 返回元组类型\n","# words, freq = zip(*words_freq)\n","# en_vocab = default_list + list(words)\n","# save_vocab(en_vocab, 'cmn-eng/en_vocab.txt')\n","\n","## 构造中文词典\n","# max_element = ch_vocab_size\n","# default_list = ['<sos>', '<eos>', '<unk>', '<pad>']\n","# char_set = Counter()\n","# with open('cmn-eng/chinese.txt','r') as ff:\n","#     for line in ff.readlines():\n","#         sentence = line.split()\n","#         temp_set = Counter(sentence)\n","#         char_set.update(temp_set)\n","# print(len(char_set))\n","# max_element -= 4\n","# words_freq = char_set.most_common(max_element) # 出现频率最大的前n个 返回元组类型\n","# words, freq = zip(*words_freq)\n","# zh_vocab = default_list + list(words)\n","# save_vocab(zh_vocab, 'cmn-eng/ch_vocab.txt')\n","\n","\n","# # 将分词后的句子 转换为词表索引序列保存\n","# en_vocab, ch_vocab = load_vocab('cmn-eng/en_vocab.txt'), load_vocab('cmn-eng/ch_vocab.txt')\n","# with open('cmn-eng/english.txt','r') as ff:\n","#     if os.path.exists('cmn-eng/en_tensor.txt'):\n","#         os.remove('cmn-eng/en_tensor.txt')\n","#     for line in ff.readlines():\n","#         if len(line) <= 1:\n","#             continue\n","#         tensor = sentence_to_tensor([line.split()], en_vocab)[0]\n","#         string = ''\n","#         for num in tensor:\n","#             string += str(num) + ' '\n","#         with open('cmn-eng/en_tensor.txt','a') as f:\n","#             f.write(string + '\\n')\n","#             f.close()\n","# with open('cmn-eng/chinese.txt','r') as ff:\n","#     if os.path.exists('cmn-eng/ch_tensor.txt'):\n","#         os.remove('cmn-eng/ch_tensor.txt')\n","#     for line in tqdm(ff.readlines(), leave=False):\n","#         if len(line) <= 1:\n","#             continue\n","#         tensor = sentence_to_tensor([line.split()], ch_vocab)[0]\n","#         string = ''\n","#         for num in tensor:  \n","#             string += str(num) + ' '\n","#         with open('cmn-eng/ch_tensor.txt','a') as f:\n","#             f.write(string + '\\n')\n","#             f.close()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 数据集构造"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:10.026699Z","iopub.status.busy":"2023-06-01T07:41:10.026350Z","iopub.status.idle":"2023-06-01T07:41:10.045949Z","shell.execute_reply":"2023-06-01T07:41:10.044981Z","shell.execute_reply.started":"2023-06-01T07:41:10.026668Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, en_path, zh_path):\n","        super().__init__()\n","        self.en_tensor = []\n","        self.zh_tensor = []\n","        \n","        with open(en_path, 'r') as f:\n","            for line in f.readlines():\n","                self.en_tensor.append([ int(num) for num in line.split()])\n","            f.close()\n","        with open(zh_path, 'r') as f:\n","            for line in f.readlines():\n","                self.zh_tensor.append([ int(num) for num in line.split()])\n","            f.close()\n","            \n","    def __len__(self):\n","        return len(self.en_tensor)\n","\n","    def __getitem__(self, index):\n","        x = np.concatenate(([SOS_ID], self.en_tensor[index], [EOS_ID]))\n","        x = torch.from_numpy(x)\n","        y = np.concatenate(([SOS_ID], self.zh_tensor[index], [EOS_ID]))\n","        y = torch.from_numpy(y)\n","        return x, y\n","\n","def collate_fn(batch):\n","    x, y = zip(*batch)\n","    x_pad = pad_sequence(x, batch_first=True, padding_value=PAD_ID)\n","    y_pad = pad_sequence(y, batch_first=True, padding_value=PAD_ID)\n","    return x_pad, y_pad\n","\n","# dataset = MyDataset(\"cmn-eng/en_tensor.txt\", \"cmn-eng/ch_tensor.txt\")\n","# loader = DataLoader(dataset, batch_size=8, shuffle=True, drop_last=False, collate_fn=collate_fn)\n","# en_vocab ,ch_vocab = load_vocab('cmn-eng/en_vocab.txt'), load_vocab('cmn-eng/ch_vocab.txt')\n","# for x, y in loader:\n","#     print(tensor_to_sentence(x[0],en_vocab))\n","#     print(tensor_to_sentence(y[0],ch_vocab))\n","#     break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# transformer"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:10.047767Z","iopub.status.busy":"2023-06-01T07:41:10.047266Z","iopub.status.idle":"2023-06-01T07:41:10.068874Z","shell.execute_reply":"2023-06-01T07:41:10.067457Z","shell.execute_reply.started":"2023-06-01T07:41:10.047729Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# 位置编码\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0, max_len=1000):\n","        super().__init__()\n","        assert d_model % 2 == 0\n","        self.dropout = nn.Dropout(dropout)\n","        P = torch.zeros((1, max_len, d_model)) # batch设为1，广播\n","        # (max_len, 1) / (d_model/2) => (max_len, d_model/2)\n","        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / torch.pow(10000, torch.arange(0, d_model, 2, dtype=torch.float32) / d_model) \n","        P[:, :, 0::2] = torch.sin(X)\n","        P[:, :, 1::2] = torch.cos(X)\n","        self.register_buffer('P', P, False) # 模型训练时不会更新 不将变量加入 state_dict\n"," \n","    def forward(self, x):\n","#         x *= x.shape[2] ** 0.5 嵌入层 的操作\n","        x = x + self.P[:, :x.shape[1], :].to(x.device)\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:10.091647Z","iopub.status.busy":"2023-06-01T07:41:10.091187Z","iopub.status.idle":"2023-06-01T07:41:10.106506Z","shell.execute_reply":"2023-06-01T07:41:10.105220Z","shell.execute_reply.started":"2023-06-01T07:41:10.091591Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# 前馈网络\n","class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.layer1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.layer2 = nn.Linear(d_ff, d_model)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.dropout(F.relu(x))\n","        x = self.layer2(x)\n","        return x\n","    \n","# 残差连接 和 层规范化\n","class AddNorm(nn.Module):\n","    def __init__(self, normalized_shape, dropout=0.1):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.ln = nn.LayerNorm(normalized_shape)\n","        \n","    def forward(self, x, y):\n","        return self.ln(x + self.dropout(y))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:10.109361Z","iopub.status.busy":"2023-06-01T07:41:10.108890Z","iopub.status.idle":"2023-06-01T07:41:10.122373Z","shell.execute_reply":"2023-06-01T07:41:10.121271Z","shell.execute_reply.started":"2023-06-01T07:41:10.109327Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n","        super().__init__()\n","        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n","        self.ffn = FeedForward(d_model, d_ff, dropout)\n","        self.addnorm1 = AddNorm(d_model, dropout)\n","        self.addnorm2 = AddNorm(d_model, dropout)\n","    \n","    def forward(self, x, padding_mask):\n","        y = self.addnorm1(x, self.attention(x, x, x, key_padding_mask=padding_mask)[0])\n","        return self.addnorm2(y, self.ffn(y))\n","    \n","    \n","class TransformerEncoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, d_ff, num_heads, num_layers, dropout=0.1):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pe = PositionalEncoding(d_model)\n","        self.blocks = nn.Sequential()\n","        for i in range(num_layers):\n","            self.blocks.add_module(f\"block{i}\", EncoderBlock(d_model, d_ff, num_heads, dropout))\n","    \n","    def forward(self, x, padding_mask=None):\n","        x = self.pe(self.embedding(x) * (self.d_model ** 0.5))\n","        for block in self.blocks:\n","            x = block(x, padding_mask)\n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:10.124360Z","iopub.status.busy":"2023-06-01T07:41:10.123649Z","iopub.status.idle":"2023-06-01T07:41:10.144988Z","shell.execute_reply":"2023-06-01T07:41:10.143780Z","shell.execute_reply.started":"2023-06-01T07:41:10.124328Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n","        super().__init__()\n","        self.attention1= nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n","        self.attention2= nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n","        self.ffn = FeedForward(d_model, d_ff, dropout)\n","        self.addnorm1 = AddNorm(d_model, dropout)\n","        self.addnorm2 = AddNorm(d_model, dropout)        \n","        self.addnorm3 = AddNorm(d_model, dropout)\n","\n","    def forward(self, x, encoder_kv, attn_mask, padding_mask):\n","        y = self.addnorm1(x, self.attention1(x, x, x, attn_mask=attn_mask)[0])\n","        z = self.addnorm2(y, self.attention2(y, encoder_kv, encoder_kv, key_padding_mask=padding_mask)[0])\n","        return self.addnorm3(z, self.ffn(z))\n","    \n","    \n","class TransformerDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, d_ff, num_heads, num_layers, dropout=0.1):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pe = PositionalEncoding(d_model)\n","        self.blocks = nn.Sequential()\n","        for i in range(num_layers):\n","            self.blocks.add_module(f\"block{i}\", DecoderBlock(d_model, d_ff, num_heads, dropout))\n","    \n","    def forward(self, x, encoder_kv, attn_mask=None, padding_mask=None):\n","        x = self.pe(self.embedding(x) * (self.d_model ** 0.5))\n","        for block in self.blocks:\n","            x = block(x, encoder_kv, attn_mask, padding_mask)\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:41:10.149078Z","iopub.status.busy":"2023-06-01T07:41:10.148716Z","iopub.status.idle":"2023-06-01T07:41:10.164404Z","shell.execute_reply":"2023-06-01T07:41:10.163431Z","shell.execute_reply.started":"2023-06-01T07:41:10.149048Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# 手搓的Transformer\n","class Transformer(nn.Module):\n","    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, d_ff, num_heads, num_layers, dropout=0.1):\n","        super().__init__()\n","        self.encoder = TransformerEncoder(src_vocab_size, d_model, d_ff, num_heads, num_layers, dropout)\n","        self.decoder = TransformerDecoder(tgt_vocab_size, d_model, d_ff, num_heads, num_layers, dropout)\n","        self.dense = nn.Sequential(nn.Linear(d_model, d_model*4), nn.ReLU(), nn.Linear(d_model*4, tgt_vocab_size))\n","        self.dense = nn.Linear(d_model, tgt_vocab_size)\n","\n","\n","    def get_padding_mask(self, src):\n","        return src == PAD_ID\n","    \n","    def get_attn_mask(self, src, tgt):\n","        return (1 - torch.tril(torch.ones((tgt.shape[1], src.shape[1]))).to(src.device)) == 1\n","    \n","    def forward(self, x, y):\n","        src_padding_mask = self.get_padding_mask(x)\n","        encoder_kv = self.encoder(x, src_padding_mask)\n","        \n","        tgt_attn_mask = self.get_attn_mask(y, y)\n","        res = self.decoder(y, encoder_kv, tgt_attn_mask, src_padding_mask)\n","        return F.log_softmax(self.dense(res), dim=-1)\n","        # return torch.matmul(res, self.decoder.embedding.weight.transpose(0, 1))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# 调库的Transformer\n","class TF(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.embedding_src = nn.Embedding(en_vocab_size, d_model).to(device)\n","        self.embedding_tgt = nn.Embedding(ch_vocab_size, d_model).to(device)\n","        self.pe = PositionalEncoding(d_model)\n","        self.model = nn.Transformer(d_model=d_model, nhead=num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers, dim_feedforward=d_ff, batch_first=True)\n","        self.dense = nn.Linear(d_model, ch_vocab_size)\n","    \n","    def forward(self, src, tgt, tgt_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask):\n","        output = self.model(src=self.pe(self.embedding_src(src)), tgt=self.pe(self.embedding_tgt(tgt)), tgt_mask=tgt_mask,\n","                       src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n","        return F.log_softmax(self.dense(output), dim=2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["class LabelSmoothing(nn.Module):\n","    \"\"\"标签平滑处理\"\"\"\n","    def __init__(self, size, padding_idx, smoothing=0.0):\n","        super(LabelSmoothing, self).__init__()\n","        self.criterion = nn.KLDivLoss(reduction='sum')\n","        self.padding_idx = padding_idx\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.size = size\n","        self.true_dist = None\n","        \n","    def forward(self, x, target):\n","        assert x.size(1) == self.size\n","        true_dist = x.data.clone()\n","        true_dist.fill_(self.smoothing / (self.size - 2))\n","        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        true_dist[:, self.padding_idx] = 0\n","        mask = torch.nonzero(target.data == self.padding_idx)\n","        if mask.dim() > 0:\n","            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","        self.true_dist = true_dist\n","        return self.criterion(x, Variable(true_dist, requires_grad=False))\n","    \n","class NoamOpt:\n","    \"Optim wrapper that implements rate.\"\n","    def __init__(self, model_size, factor, warmup, optimizer):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.warmup = warmup\n","        self.factor = factor\n","        self.model_size = model_size\n","        self._rate = 0\n","        \n","    def step(self):\n","        \"Update parameters and rate\"\n","        self._step += 1\n","        rate = self.rate()\n","        for p in self.optimizer.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","        self.optimizer.step()\n","        \n","    def rate(self, step = None):\n","        \"Implement `lrate` above\"\n","        if step is None:\n","            step = self._step\n","        return self.factor * (self.model_size ** (-0.5) * min(step ** (-0.5), step * self.warmup ** (-1.5)))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["load model\n"]}],"source":["model = Transformer(en_vocab_size, ch_vocab_size, d_model, d_ff, num_heads, num_layers)\n","# model = TF()\n","for m in model.modules():\n","    if isinstance(m, (nn.Conv2d, nn.Linear)):\n","        nn.init.xavier_uniform_(m.weight)\n","if os.path.exists('transformer.pth'):\n","    print('load model')\n","    model.load_state_dict(torch.load('transformer.pth',map_location=device))\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-01T07:42:47.492052Z","iopub.status.busy":"2023-06-01T07:42:47.491615Z","iopub.status.idle":"2023-06-01T07:47:37.315862Z","shell.execute_reply":"2023-06-01T07:47:37.314139Z","shell.execute_reply.started":"2023-06-01T07:42:47.492011Z"},"trusted":true},"outputs":[],"source":["# opt = optim.Adam(model.parameters(), lr=lr)\n","# Loss = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n","opt= NoamOpt(d_model, 2, (int)(num_epochs * (29476 / batch_size) * 0.1), torch.optim.Adam(model.parameters(), lr=0, betas=(0.9,0.98), eps=1e-9))\n","opt._step = (int)(num_epochs * (29476 / batch_size))\n","Loss = LabelSmoothing(ch_vocab_size, padding_idx = PAD_ID, smoothing= 0.0)\n","min_loss =  1 \n","plt.ion()\n","for epoch in range(num_epochs):\n","    torch.cuda.empty_cache()\n","    model = model.to(device)\n","    model.train()\n","    loop = tqdm(loader, leave=False)\n","    loss_sum = 0\n","    token_sum = 0\n","    correct = 0\n","    correct_sum = 0\n","    for idx, (x, y) in enumerate(loop):\n","        src, tgt = x.to(device), y[:, :-1].to(device)\n","        \n","        # src_key_padding_mask = memory_key_padding_mask = (src == PAD_ID).to(device)\n","        # tgt_key_padding_mask = (tgt == PAD_ID).to(device)\n","        # tgt_mask = (model.model.generate_square_subsequent_mask(tgt.shape[1]) == -math.inf).to(device)\n","\n","        # y_hat = model(src=src, tgt=tgt, tgt_mask=tgt_mask,\n","        #             src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n","\n","        y_hat = model(src, tgt)\n","        \n","        tokens = (y[:, 1:] != PAD_ID).sum()\n","        loss = Loss(y_hat.reshape(-1, y_hat.size(-1)), y[:, 1:].long().reshape(-1).to(device)) / tokens\n","        if math.isnan(loss.item()):\n","            raise Exception\n","        \n","        # opt.zero_grad()\n","        opt.optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        opt.step()\n","        \n","        loss_sum += loss.item() * tokens\n","        token_sum +=  tokens\n","        correct += ((y[:, 1:].to(device) == y_hat.argmax(-1)) * (y[:, 1:].to(device) != PAD_ID)).sum()\n","        correct_sum += (y[:, 1:].to(device) != PAD_ID).sum()\n","    \n","    plt.subplot(3, 1 ,1)\n","    plt.plot(epoch+1, (loss_sum/token_sum).cpu(), '.', color='red')\n","    plt.subplot(3, 1,2)\n","    plt.plot(epoch+1, (correct/correct_sum).cpu(), '.', color='blue')\n","    plt.subplot(3, 1,3)\n","    plt.plot(opt._step, opt._rate, '.', color='green')\n","    plt.tight_layout()\n","    display.clear_output(wait=True)\n","    display.display(plt.gcf())\n","    \n","    print(f\"epoch {epoch + 1} loss {loss_sum / token_sum}  acc:{correct / correct_sum}\")\n","    if loss_sum / token_sum < min_loss:\n","        min_loss = loss_sum / token_sum\n","        # torch.save(model.state_dict(), 'transformer.pth')\n","        print(\"save model\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# evacuate"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["load model\n"]}],"source":["valid_dataset = MyDataset(\"cmn-eng/en_tensor_valid.txt\", \"cmn-eng/ch_tensor_valid.txt\")\n","valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True, drop_last=False, collate_fn=collate_fn)\n","en_vocab, ch_vocab = load_vocab('cmn-eng/en_vocab.txt'), load_vocab('cmn-eng/ch_vocab.txt')\n","model = Transformer(en_vocab_size, ch_vocab_size, d_model, d_ff, num_heads, num_layers)\n","if os.path.exists('transformer.pth'):\n","    print('load model')\n","    model.load_state_dict(torch.load('transformer.pth',map_location=device))\n","model = model.to(device)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import collections\n","\n","def bleu(pred_seq, label_seq, k): #@save\n","    \"\"\"计算BLEU\"\"\"\n","    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n","    len_pred, len_label = len(pred_tokens), len(label_tokens)\n","    score = math.exp(min(0, 1 - len_label / len_pred))\n","    for n in range(1, k + 1):\n","        num_matches, label_subs = 0, collections.defaultdict(int)\n","        for i in range(len_label - n + 1):\n","            label_subs[' '.join(label_tokens[i: i + n])] += 1\n","        for i in range(len_pred - n + 1):\n","            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n","                num_matches += 1\n","                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n","        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n","    return score"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the man is loading the moving truck on his own .\n","這個 男人 獨自 把 東西 搬 上 搬家 卡車 上 。\n","完全 是 自己 的 电话 。\n","0.17742397566167217\n"]}],"source":["for x, y in valid_loader:\n","    target = torch.tensor([[SOS_ID]] * y.shape[0])\n","    model.eval()\n","    for i in range(y.shape[1]): \n","        src, tgt = x[0:1].to(device), target[0:1].to(device)\n","        # src_key_padding_mask = memory_ke y_padding_mask = (src == PAD_ID).to(device)\n","        # tgt_key_padding_mask = (tgt == PAD_ID).to(device) \n","        # tgt_mask = model.model.generate_square_subsequent_mask(tgt.shape[1]).to(device)     \n","        \n","        # y_hat = model(src, tgt, tgt_mask=tgt_mask,\n","        #               src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n","        y_hat = model(src, tgt)\n","\n","        out = torch.argmax(y_hat[:, -1, :], dim=-1)\n","        if out == EOS_ID:\n","            break\n","        target = torch.concat([target[0:1].to(device), out.unsqueeze(1).to(device)], dim=1)\n","        \n","    \n","    origin = tensor_to_sentence(y[0, 1: -1], ch_vocab)\n","    trans =  tensor_to_sentence(target[0, 1:], ch_vocab)\n","    print(tensor_to_sentence(x[0, 1: -1], en_vocab))\n","    print(origin)\n","    print(trans)    \n","    print(bleu(trans, origin, k=1))  \n","    \n","    break"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<sos> it ' s hard to predict what the weather will be like tomorrow . <eos>\n","<sos> 很难说 明天 的 天气 将会 怎样 。 <eos>\n","73866 : 天氣 并 一起 曾 。 。\n","42938 : 天氣 并 一起 。 。 。\n","6295 : 天氣 怎麼樣 。 幾個 天氣 ？\n","3049 : 天氣 怎麼樣 。 幾個 天气 了\n","2283 : 天氣 怎麼樣 。 幾個 天氣 。\n","2256 : 明天 的 天氣 他 喜歡 。\n"]}],"source":["ans = []\n","def beam_search(model, src, tgt=None, max_len=1, k=2, pr=1):\n","    model.eval()\n","    if tgt is None:\n","        tgt = torch.tensor([SOS_ID]).to(device)\n","    \n","    if tgt.shape[0] >= max_len:\n","        ans.append([tensor_to_sentence(tgt[1:], ch_vocab), (int)(pr)])\n","        return\n","    \n","    y_hat = model(src.unsqueeze(0), tgt.unsqueeze(0))\n","    vals, idxs = torch.sort(y_hat[0, -1, :], descending=True)\n","    for i in range(k):\n","        idx = idxs[i]\n","        if idx == EOS_ID:\n","            ans.append([tensor_to_sentence(tgt[1:], ch_vocab), (int)(pr)])\n","            continue\n","        beam_search(model, src, torch.cat([tgt, idx.unsqueeze(0)], dim=0), max_len, k, vals[i]*pr)\n","\n","for x, y in valid_loader:\n","    x, y = x[0].to(device), y[0].to(device)\n","    beam_search(model, x, tgt=None, max_len=(y!=PAD_ID).sum()-1, k=2, pr=1)\n","    \n","    print(tensor_to_sentence(x, en_vocab))\n","    print(tensor_to_sentence(y, ch_vocab))   \n","    \n","    ans = sorted(ans , key=lambda ans:ans[1], reverse=True)\n","    for i in range(min(6, len(ans))):\n","        print(ans[i][1], \":\", ans[i][0])\n","    break\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\lzr\\AppData\\Local\\Temp\\ipykernel_17748\\3506470542.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n","  x = torch.tensor(sentence_to_tensor([english], en_vocab)).to(device)\n"]},{"data":{"text/plain":["'<sos> 湯姆 是 我 的 名字 。 <eos>'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["def translate_english2chinese(model, english, en_vocab, ch_vocab):\n","    assert is_contain_chinese(english) == False , \"该句子包含中文\"\n","    tokenizer = get_tokenizer('basic_english')\n","    english = tokenizer(english)\n","    x = torch.tensor(sentence_to_tensor([english], en_vocab)).to(device)\n","    y = torch.tensor([[SOS_ID]]).to(device)\n","    model = model.to(device)\n","    model.eval()\n","    while True:\n","        src, tgt = x[0:1].to(device), y[0:1].to(device)\n","        y_hat = model(src, tgt)\n","        out = torch.argmax(y_hat[:, -1, :], dim=-1)\n","        y = torch.concat([y[0:1].to(device), out.unsqueeze(1).to(device)], dim=1)\n","        if out == EOS_ID:\n","            break\n","\n","    return tensor_to_sentence(y[0], ch_vocab)\n","\n","translate_english2chinese(model, \"my name is Tom .\", en_vocab, ch_vocab)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
